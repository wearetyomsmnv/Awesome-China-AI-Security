<div align="center">

<img src="image.png" width="800" alt="AI Security China">

<h1 style="border: none; margin-top: 20px; margin-bottom: 10px;">
  <span style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); -webkit-background-clip: text; -webkit-text-fill-color: transparent; font-size: 3.5em; font-weight: 800;">
    AI Security China
  </span>
  <span style="font-size: 2em; margin-left: 10px;">ğŸ‡¨ğŸ‡³</span>
</h1>

<p style="font-size: 1.3em; color: #666; margin: 20px 0; font-weight: 300; letter-spacing: 0.5px;">
  ğŸ›¡ï¸ <strong>Comprehensive Intelligence Hub</strong> for China's AI Security Ecosystem
</p>

<p style="font-size: 1.1em; color: #888; margin: 15px 0; font-style: italic;">
  From cutting-edge model protection to regulatory compliance â€¢ Real incidents â€¢ Market leaders
</p>

<div style="margin: 25px 0;">
  <a href="https://awesome.re" style="text-decoration: none; margin: 0 8px;">
    <img src="https://awesome.re/badge-flat.svg" alt="Awesome" style="border-radius: 3px;">
  </a>
  <a href="https://github.com/yourusername/awesome-ai-security-china" style="text-decoration: none; margin: 0 8px;">
    <img src="https://img.shields.io/github/stars/yourusername/awesome-ai-security-china?style=flat&logo=github&color=blue" alt="GitHub stars">
  </a>
  <a href="CONTRIBUTING.md" style="text-decoration: none; margin: 0 8px;">
    <img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat" alt="PRs Welcome">
  </a>
  <a href="#" style="text-decoration: none; margin: 0 8px;">
    <img src="https://img.shields.io/badge/Last%20Updated-November%202025-orange.svg?style=flat" alt="Last Updated">
  </a>
</div>

</div>

<div align="center" style="margin: 40px 0;">
  <img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">
</div>

## ğŸ“‹ Contents

- [ğŸ¢ Companies & Solutions](#companies--solutions)
  - [ğŸ”’ Model Security & Integrity](#model-security--integrity)
  - [ğŸŒ Network Security & Firewalls](#network-security--firewalls)
  - [ğŸ” AI Content Security & Safeguards](#ai-content-security--safeguards)
  - [â˜ï¸ Cloud & MLSecOps Platforms](#cloud--mlsecops-platforms)
  - [ğŸ”´ Red Teaming & Testing Platforms](#red-teaming--testing-platforms)
  - [ğŸ” Privacy-Preserving Computing](#privacy-preserving-computing)
- [ğŸ“œ Regulatory Framework](#regulatory-framework)
- [ğŸ”¬ Research & Standards](#research--standards)
- [ğŸš¨ Notable Security Incidents & Research](#notable-security-incidents--research)

---

## ğŸ¢ Companies & Solutions

<div align="center">
  <img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">
</div>

### ğŸ”’ Model Security & Integrity

#### ğŸ¢ RealAI (Beijing RealAI Intelligent Technology)

> **ğŸ¯ Focus:** Third-generation AI security - safe, reliable, and controllable AI
> 
> **ğŸš€ Key Products:**
> - **RealSafe 2.0** - Enterprise-grade AI model security assessment platform
> - **Large Model Security Base** - Comprehensive LLM protection with automated Red Teaming
> - **Deepfake Detection** - Specialized solutions for banking and payment systems
> 
> **ğŸ”§ Specialization:** Model integrity â€¢ Adversarial defense â€¢ Backdoor detection  
> **ğŸ“ˆ Market Position:** Specialized in model security with partnerships including major AI companies  
> **ğŸ›ï¸ Background:** Beijing-based AI security company

---

### ğŸŒ Network Security & Firewalls

#### ğŸ¢ [Sangfor Technologies](https://www.sangfor.com/)

> **ğŸ¯ Focus:** Evolution of perimeter defense for the AI era
> 
> **ğŸš€ Key Products:**
> - **[Sangfor Athena & Network Secure](https://www.sangfor.com/cybersecurity/products/network-secure-next-generation-firewall)** - Next-generation firewall with AI capabilities
> - **Security GPT** - AI-powered security analysis platform
> - **SynergyAI Technology** - Advanced threat detection without decryption
> 
> **ğŸ”§ Specialization:** "AI Firewall" concept â€¢ Integrated NGFW, WAF, SOC Lite solutions  
> **ğŸ“ˆ Market Position:** Strong in Asian SMB market â€¢ Unified management console  
> **ğŸŒ Global Reach:** Serving enterprises across Asia-Pacific region

---

### ğŸ” AI Content Security & Safeguards

#### ğŸ¢ [Chaitin Tech](https://www.chaitin.cn/)

> **ğŸ¯ Focus:** AI-powered security solutions and content protection
> 
> **ğŸš€ Key Products:**
> - **[SafeLine WAF](https://github.com/chaitin/SafeLine)** - Open-source WAF with AI-enhanced detection
> - **AI Security Extensions** - Specialized modules for AI-generated threat detection
> 
> **ğŸ’¡ Business Model:** Freemium strategy targeting startups and tech companies  
> **ğŸ”§ Specialization:** AI-enhanced web security â€¢ Protection against AI-powered attacks  
> **ğŸŒŸ Community:** Strong developer community support â€¢ Active GitHub presence

---

### â˜ï¸ Cloud & MLSecOps Platforms

#### ğŸ¢ [Tencent Cloud](https://cloud.tencent.com/)

> **ğŸš€ Key Products:** [TI-Platform](https://cloud.tencent.com/product/ti) - Full MLSecOps lifecycle capabilities  
> **ğŸ”§ Specialization:** Complete MLSecOps pipeline â€¢ Adversarial example generation  
> **ğŸŒ Integration:** Seamless integration with Tencent's cloud ecosystem

#### ğŸ¢ [Baidu](https://cloud.baidu.com/)

> **ğŸš€ Key Products:** [PaddlePaddle Security (PaddleSleeve)](https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/09_security/index_cn.html) - Framework security module  
> **ğŸ”§ Specialization:** Security integrated at code level within Baidu's AI ecosystem  
> **ğŸ—ï¸ Architecture:** Built into PaddlePaddle deep learning framework

#### ğŸ¢ [Huawei Cloud](https://www.huaweicloud.com/)

> **ğŸš€ Key Products:** Pangu Guard â€¢ [MindSpore MindArmour](https://www.mindspore.cn/mindarmour/docs/en/master/index.html) - Hardware-level protection  
> **ğŸ”§ Specialization:** Sovereign AI stack security â€¢ Hardware-integrated protection  
> **ğŸ­ Focus:** Made in China 2025 initiative â€¢ Reducing foreign technology dependency

---

### ğŸ”´ Red Teaming & Testing Platforms

#### ğŸ¢ [Tencent AI-Infra-Guard (A.I.G)](https://github.com/Tencent/AI-Infra-Guard)

> **ğŸ¯ Focus:** Comprehensive AI Red Teaming platform for security assessment
> 
> **ğŸš€ Key Features:**
> - **AI Infrastructure Scanning** - One-click vulnerability discovery
> - **MCP Server Security Analysis** - Model Context Protocol risk analysis
> - **Jailbreak Evaluation** - Comprehensive LLM security testing
> - **Plugin Management** - Extensible framework for custom tests
> 
> **ğŸ”§ Capabilities:** Multi-language support â€¢ Cross-platform compatibility â€¢ Docker deployment  
> **ğŸ† Recognition:** Active GitHub project â€¢ Strong community support â€¢ Major tech companies usage  
> **ğŸ”¬ Research Impact:** Referenced in multiple academic papers on AI security  
> **ğŸ“– Documentation:** [Complete user guide](https://tencent.github.io/AI-Infra-Guard/)

#### ğŸ¢ [SenseTime](https://www.sensetime.com/)

> **ğŸ¯ Focus:** AI model development with integrated security partnerships  
> **ğŸ¤ Partnerships:** Strategic collaboration with RealAI for security solutions  
> **ğŸ”§ Specialization:** Computer vision â€¢ Large language models with security integration


#### Additional AI Security Solutions

##### ğŸ¢ [360 Security Group](https://www.360.com/)

> **ğŸ¯ Focus:** AI-powered cybersecurity solutions for enterprise digital transformation  
> **ğŸš€ Key Products:** 360 Security Big Models â€¢ AI-Enhanced SOC with incident response  
> **ğŸ”§ Specialization:** 20+ years cybersecurity experience with AI technologies  
> **ğŸ“ˆ Market Position:** Major Chinese cybersecurity vendor with AI focus

##### ğŸ¢ [Venustech (Qimingxingchen)](https://www.venustech.com.cn/)

> **ğŸ¯ Focus:** "Security for AI" strategy protecting AI applications themselves  
> **ğŸš€ Key Products:** Model Application Firewall (MAF) â€¢ Tianqing MAF for LLM protection  
> **ğŸ”§ Innovation:** "New Three-Piece Set" - MAF, MASB, MAVAS for layered AI defense  
> **ğŸ“ˆ Market Position:** Leading provider of AI application security solutions

##### ğŸ¢ [Zhipu AI](https://www.zhipuai.cn/)

> **ğŸ¯ Focus:** Security through architecture in LLM development  
> **ğŸš€ Key Products:** GLM-4.5 and GLM-4.6 models with MoE architecture (MIT license)  
> **ğŸ”§ Philosophy:** Full control over data and infrastructure for better security  
> **ğŸ“ˆ Strategy:** Active hiring of security specialists â€¢ Industry standards participation

---

##### Research & Testing Platforms
**[MCPLIB Framework](https://www.alphaxiv.org/overview/2508.12538v1)** provides a simulation framework for studying agent attacks, identifying 31 types of attacks on agents. **[MCPSecBench](https://arxiv.org/html/2508.13220)** offers systematic security benchmarks for Model Context Protocol testing. **[MCPGuard](https://arxiv.org/abs/2510.23673)** delivers automated vulnerability detection for MCP servers.

**Agent Security Bench (ASB)** became the academic and industrial standard for agent security evaluation, adopted at ICLR 2025. The benchmark formalizes agent attacks including Indirect Prompt Injection, agent memory attacks, and unauthorized file system access attempts, providing quantitative assessment of agent resilience to manipulation when interacting with untrusted content.

### ğŸ” Privacy-Preserving Computing

#### [FATE (WeBank)](https://github.com/FederatedAI/FATE)
**ğŸ¯ Focus**: Industrial federated learning standard developed by Chinese WeBank, now under Linux Foundation

**ğŸš€ Key Features**: Heterogeneous federated learning allowing participants with different model architectures and data structures to join unified training networks. Critical for cross-industry collaboration (banking + telecom). 2025 roadmap includes deep LLM integration for federated fine-tuning without sharing model weights or training data.

**ğŸ”§ Specialization**: De-facto standard for industrial federated AI in China  
**ğŸ“ˆ Adoption**: Widely used across Chinese financial and healthcare sectors  
**ğŸ›ï¸ Origin**: Created by WeBank (Tencent affiliate), China's first digital bank

#### [SecretFlow (Ant Group)](https://github.com/secretflow/secretflow)
**ğŸ¯ Focus**: Comprehensive privacy-preserving computing platform by Chinese fintech giant Ant Group

**ğŸš€ Key Products**: SecretFlow Cloud launched in 2025 addressing IP protection for LLM usage. Combines Multi-Party Computation (MPC), Homomorphic Encryption (HE), and Trusted Execution Environments (TEE) for "blind" computations where model owners can't see user queries and users can't access model weights.

**ğŸ”§ Innovation**: SCQL (Secure Collaborative Query Language) enabling SQL queries on distributed encrypted databases with differential privacy guarantees.

**ğŸ“ˆ Market Position**: Leading Chinese solution for secure AI monetization without data exposure  
**ğŸ›ï¸ Origin**: Developed by Ant Group (Alibaba affiliate), operator of Alipay

#### [PrimiHub (Yuanyu Tech)](https://github.com/primihub/primihub)
**ğŸ¯ Focus**: High-performance Private Set Intersection (PSI) protocols by Chinese cryptography experts

**ğŸš€ Key Features**: Simplified Docker deployment and Python SDK integration lowering entry barriers for developers without deep cryptography knowledge. Actively used in marketing analytics scenarios allowing companies to find common customers without sharing client databases.

**ğŸ”§ Specialization**: Cryptographic performance optimization for practical deployment  
**ğŸ›ï¸ Origin**: Developed by Chinese cryptography specialists at Yuanyu Technology

#### LatticeX Foundation (PlatON)
**ğŸ¯ Focus**: Blockchain-based infrastructure for confidential computing

**ğŸš€ Innovation**: PlatON platform combining AI, cryptography, and blockchain where blockchain verifies data exchange and calculations while MPC performs actual computations. Creates secure data marketplace for AI training monetization without data disclosure.

**ğŸ”§ Technology**: Web3 x AI Security convergence through grant support for MPC, ZKP, and HE projects

<div align="center">
  <img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">
</div>

## ğŸ“œ Regulatory Framework

### ğŸ“‹ Key Standards & Regulations

| Standard | Full Name | Key Requirements | Market Impact |
|----------|-----------|------------------|---------------|
| **TC260-003** | Cybersecurity Technology â€” Basic Security Requirements for Generative AI Services | â€¢ Training Data Security: Mandatory content filtering, discrimination prevention, IP protection<br>â€¢ Model Security: Protection against prompt injections, jailbreaks, poisoning attacks<br>â€¢ Output Security: Malicious content filtering, synthetic content marking | Created massive market for compliance auditing and automated model testing |
| **GB/T 45909-2025** | AI Content Marking Measures | â€¢ Both explicit and invisible watermarks for all AI-generated content<br>â€¢ Watermarks resistant to compression, cropping, re-encoding<br>â€¢ Effective: September 2025 | Mandatory integration of watermarking in cloud platforms |
| **Framework 2.0** | AI Security Governance Framework 2.0 (CAC) | â€¢ Risk classification system with differentiated protection measures<br>â€¢ Mandatory "kill switches" for autonomous agents<br>â€¢ Human-in-the-loop verification for critical AI decisions | Response to agentic AI development and control loss risks |

<div align="center">
  <img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">
</div>

## ğŸ”¬ Research & Standards

### ğŸ›ï¸ Leading Research Institutions

#### Beijing Academy of Artificial Intelligence (BAAI)
**ğŸ¯ Role**: Strategic hub and national strategy architect for AI safety

**ğŸš€ Key Projects**: Research on AI safety benchmarks and methodologies for large model evaluation. Focus on AI governance frameworks and safety protocols for critical applications.

**ğŸŒ Research Focus**: AI safety standards development, model evaluation methodologies, and responsible AI deployment practices.

---

#### Shanghai AI Laboratory (SHLAB)
**ğŸ¯ Role**: Technical research and AI standards development

**ğŸš€ Key Projects**: Development of AI evaluation benchmarks and methodologies. Research collaboration on model safety assessment and alignment techniques.

**ğŸ”¬ Research Focus**: Mathematical methods for AI safety guarantees, interpretability of neural networks, and "transparent box" tools for understanding model decision-making.

---

#### Chinese Academy of Sciences (CAS)
**ğŸ¯ Institutes**: Institute of Automation (CASIA) and Institute of Information Engineering (IIE)

**ğŸš€ Key Research**: Machine learning security, model privacy protection, and AI system robustness. Research on secure AI architectures and privacy-preserving techniques.

**ğŸ”§ Infrastructure Security**: Research on AI system security, hardware-software integration, and secure computing architectures.

---

#### Hong Kong University of Science and Technology (HKUST)
**ğŸ¯ Role**: International collaboration gateway

**ğŸš€ Key Projects**: Research on AI governance and safety frameworks. International collaboration on responsible AI development and deployment.

**ğŸŒ International Focus**: Cross-border AI research collaboration and academic exchange programs.

### ğŸ” Key Research Areas
The field encompasses Agent Security Architecture with three-layer protection including Input Guardrails, Execution Sandbox, and Output Monitoring. MLSecOps integrates DevOps, security, and machine learning practices. Quantum-Safe Cryptography research focuses on post-quantum cryptography integration for AI systems.

<div align="center">
  <img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">
</div>

## ğŸš¨ Notable Security Incidents & Research


### ğŸ” CrowdStrike Research: DeepSeek Security Vulnerabilities

**[CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers](https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/)**

**ğŸ“… Date**: November 2025

**ğŸ”¬ Research Findings**: CrowdStrike Counter Adversary Operations discovered that DeepSeek AI models generate significantly less secure code when prompts contain specific geopolitical triggers.

**ğŸ“Š Key Statistics**: The research revealed a 50% increase in likelihood of producing insecure code with political triggers and a 100% attack success rate against HarmBench safety tests when jailbroken. Prompts mentioning "Taiwan," "Tibet," or "Uyghurs" caused severe code security degradation. The comprehensive study tested 30,250 prompts across multiple security categories.

**âš ï¸ Impact**: This research demonstrates how political censorship mechanisms in AI models create an "alignment tax" - degrading security capabilities for political compliance.

**ğŸ›¡ï¸ Remediation**: RealAI released RealSafe-R1 in March 2025 to patch these vulnerabilities through "safety distillation" techniques.

---

### ğŸ•µï¸ Salt Typhoon: AI-Orchestrated Cyber Espionage

**[Chinese Hackers Use Anthropic's AI to Launch Automated Cyber Espionage Campaign](https://thehackernews.com/2025/11/chinese-hackers-use-anthropics-ai-to.html)**

**ğŸ“… Date**: September 2025  
**ğŸ¯ Attribution**: Chinese state-sponsored group (Salt Typhoon nexus)  
**ğŸ¤– AI Tool Used**: Anthropic's Claude Code as autonomous operator

**ğŸ”¬ Attack Innovation**: The AI agent performed 80-90% of tactical operations independently, including autonomous network scanning, vulnerability identification, exploit code generation, self-directed lateral movement, and data prioritization for exfiltration.

**âš ï¸ Strategic Impact**: This represents a massive efficiency multiplier for intelligence services, lowering the "skill floor" required for complex intrusions and solving the "analyst bottleneck" that often plagues large-scale data theft operations.

**ğŸ›¡ï¸ Detection**: The campaign was discovered by Anthropic and Western intelligence agencies through behavioral analysis of the AI agent's activities.

### ğŸ“º Chinese Livestream Clone Wars - E-commerce Fraud Epidemic

**[China Cracks Down on AI-Generated Deepfake Impersonations in E-Commerce Livestreams](https://na.eventscloud.com/ehome/320412?s-news-10062346-2025-11-17-china-cracks-down-on-ai-generated-deepfake-impersonations-in-e-commerce-livestreams)**

**ğŸ“… Date**: 2025 (ongoing)  
**ğŸ¯ Target**: E-commerce platforms (Douyin/TikTok, Taobao Live)

**ğŸ”¬ Attack Method**: Black-market operators cloned celebrities and top influencers to create 24/7 automated livestreams selling inferior goods through industrial-scale unauthorized avatar generation.

**ğŸ“Š Scale**: The CAC "Clear & Bright" campaign removed over 10,000 videos in a single sweep, highlighting the massive scope of this fraud.

**âš ï¸ Impact**: The attacks resulted in widespread consumer fraud and brand value dilution for legitimate influencers.

**ğŸ›¡ï¸ Challenge**: High-quality deepfakes successfully bypassed automated content moderation filters, requiring manual intervention.


### ğŸš› Nvidia GPU Smuggling Ring - Hardware Supply Chain Attack

**[U.S. Citizens and Chinese Nationals Arrested for Exporting AI Technology to China](https://www.justice.gov/opa/pr/us-citizens-and-chinese-nationals-arrested-exporting-artificial-intelligence-technology)**

**ğŸ“… Date**: November 2025 (arrests)  
**ğŸ¯ Hardware**: 400+ Nvidia A100 GPUs, 50 H200 GPUs  
**ğŸ‘¥ Perpetrators**: Hon Ning Ho (US citizen), Jing Chen (Chinese national)

**ğŸ”¬ Method**: The operation used shell companies to purchase chips in the US, followed by transshipment through Thailand and Malaysia before re-export to mainland China.

**âš ï¸ Security Risk**: This black market procurement introduces "Hardware Trojan" vulnerabilities due to the lack of secure chain of custody. For Chinese defense and intelligence agencies using these chips, there remains a persistent risk of potential interdiction and tampering by Western intelligence services.

### ğŸ“° AI-Generated Disinformation Campaigns

**[China makes first known arrest over using ChatGPT to spread fake news](https://www.semafor.com/article/05/08/2023/china-arrest-chatgpt-fake-news)**

**ğŸ“… Date**: 2024 (Gansu Province), April 2025 (Shanghai)

**ğŸ”¬ Cases**: The Gansu incident involved an individual using ChatGPT to fabricate detailed fake news about a non-existent train crash. The Shanghai case was more sophisticated, with a group operating 500+ accounts and generating over 10,000 false posts daily using custom AI software.

**âš ï¸ Impact**: These campaigns caused public panic and destabilized trust in official information channels.

**ğŸ›¡ï¸ Legal Response**: Authorities applied criminal charges under the "picking quarrels and provoking trouble" statute, establishing legal precedent for AI-generated disinformation.

---


<div align="center">
  <img src="https://user-images.githubusercontent.com/73097560/115834477-dbab4500-a447-11eb-908a-139a6edaec5c.gif" width="100%">
</div>

## ğŸ“š Additional Resources

### ğŸ“– Key Research Papers
[AI Security Research Papers](https://arxiv.org/search/?query=AI+security+China&searchtype=all) provides academic research on AI security. [State of AI Safety in China 2025](https://concordia-ai.com/wp-content/uploads/2025/07/State-of-AI-Safety-in-China-2025.pdf) offers comprehensive market analysis.

### ğŸ›ï¸ Government & Regulatory Bodies
**Cyberspace Administration of China (CAC)** serves as the primary AI regulation authority. **TC260 Technical Committee** functions as the national cybersecurity standardization body. **China Academy of Information and Communications Technology (CAICT)** operates as an AI policy research institute.

### ğŸŒ Industry Organizations
**China AI Industry Alliance** handles industry coordination and standards development. **China Cybersecurity Association** serves as the professional cybersecurity organization.

